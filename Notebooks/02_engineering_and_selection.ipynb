{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # Version: 1.24.3\n",
    "import pandas as pd                 # Version: 1.5.3\n",
    "from   pandas.api.types import CategoricalDtype\n",
    "import geopandas as gpd             # Version: 1.4.0\n",
    "import fiona                        # Version: 1.16.0\n",
    "import seaborn as sns               # Version: 0.13.2\n",
    "import matplotlib.pyplot as plt     # Version: 3.8.2\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from   matplotlib.patches import Patch\n",
    "from   matplotlib.font_manager import FontProperties\n",
    "import scipy                        # Version: 1.10.1\n",
    "from   scipy.stats import zscore, genpareto, gaussian_kde\n",
    "import statsmodels                  # Version: 0.14.0\n",
    "from   statsmodels.tsa.seasonal import STL\n",
    "import sklearn                      # Version: 1.3.0\n",
    "from   sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from   sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Python version: 3.11.4\n",
    "import os\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "parent_dir   = os.path.dirname(notebook_dir)\n",
    "target_dir   = os.path.join(parent_dir, \"Data\")\n",
    "\n",
    "# Historical wildfires\n",
    "csv_path = os.path.join(target_dir, \"01_historical_wildfires.csv\")\n",
    "fires    = pd.read_csv(csv_path)\n",
    "fires[\"fire\"] = True # Add a fire indicator column\n",
    "fires = fires.rename(columns={\"ignition_date\": \"Date\", \"state\": \"State\"})\n",
    "\n",
    "# Weather metrics\n",
    "csv_path = os.path.join(target_dir, \"02_weather_metrics.csv\")\n",
    "weather  = pd.read_csv(csv_path)\n",
    "\n",
    "# NDVI\n",
    "csv_path = os.path.join(target_dir, \"03_NDVI.csv\")\n",
    "ndvi     = pd.read_csv(csv_path)\n",
    "ndvi[\"Date\"]  = pd.to_datetime(ndvi[\"Date\"])\n",
    "ndvi[\"year\"]  = ndvi[\"Date\"].dt.year\n",
    "ndvi[\"month\"] = ndvi[\"Date\"].dt.month\n",
    "\n",
    "# Merge weather and fires: LEFT JOIN so all weather dates are preserved\n",
    "df = weather.merge(fires, on=[\"Date\", \"State\"], how=\"left\")\n",
    "df[\"fire\"]  = df[\"fire\"].notna() # Complete fire indicator column\n",
    "# Extract year and month from weather-fire dataset\n",
    "df[\"Date\"]  = pd.to_datetime(df[\"Date\"])\n",
    "df[\"year\"]  = df[\"Date\"].dt.year\n",
    "df[\"month\"] = df[\"Date\"].dt.month\n",
    "\n",
    "# Merge NDVI based on state-year-month\n",
    "df = df.merge(ndvi.drop(columns=\"Date\"), on=[\"State\", \"year\", \"month\"], how=\"left\")\n",
    "df = df.drop(columns=[\"year\", \"month\"])\n",
    "df = df.loc[:, ~df.columns.str.startswith('Unnamed')] # Drop all columns whose names start with \"Unnamed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['State', 'Date', 'Temperature [°C]_mean', 'Relative humidity [%]_mean',\n",
      "       'Wind speed [m/s]_mean', 'Precipitation [mm/day]_sum',\n",
      "       'Solar radiation [Jm2/day]_sum', 'Temperature [°C]_min',\n",
      "       'Relative humidity [%]_min', 'Wind speed [m/s]_min',\n",
      "       'Precipitation [mm/day]_min', 'Solar radiation [Jm2/day]_min',\n",
      "       'Temperature [°C]_max', 'Relative humidity [%]_max',\n",
      "       'Wind speed [m/s]_max', 'Precipitation [mm/day]_max',\n",
      "       'Solar radiation [Jm2/day]_max', 'Temperature [°C]_std',\n",
      "       'Relative humidity [%]_std', 'Wind speed [m/s]_std',\n",
      "       'Precipitation [mm/day]_std', 'Solar radiation [Jm2/day]_std',\n",
      "       'total_area_ha', 'log_total_area_ha', 'fire_count', 'outlier_type',\n",
      "       'ignition_cause', 'fire', 'NDVI_min', 'NDVI_max', 'NDVI_mean',\n",
      "       'NDVI_std', 'NDVI_var', 'Temperature_trend', 'Temperature_residual',\n",
      "       'Humidity_trend', 'Humidity_residual', 'NDVI_trend', 'NDVI_residual',\n",
      "       'Solar_de-seasonalized'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "### FEATURE ENGINEERING ###\n",
    "\n",
    "df_engineered = df.copy()\n",
    "df_engineered['Date']      = pd.to_datetime(df_engineered['Date'])\n",
    "df_engineered['YearMonth'] = df_engineered['Date'].dt.to_period('M')\n",
    "\n",
    "stl_features = {\n",
    "    'Temperature [°C]_mean': 'Temperature',\n",
    "    'Relative humidity [%]_mean': 'Humidity',\n",
    "    'NDVI_mean': 'NDVI'\n",
    "}\n",
    "\n",
    "# Solar radiation variable to de-seasonalize\n",
    "solar_radiation_col  = 'Solar radiation [Jm2/day]_sum'\n",
    "\n",
    "stl_monthly_features = []\n",
    "# Process per state\n",
    "for state in df_engineered['State'].unique():\n",
    "    df_state = df_engineered[df_engineered['State'] == state]\n",
    "    # Only keep numeric columns + YearMonth\n",
    "    numeric_cols = df_state.select_dtypes(include=np.number).columns\n",
    "    df_monthly   = df_state.groupby('YearMonth')[numeric_cols].mean().reset_index()\n",
    "    df_monthly['YearMonth']  = df_monthly['YearMonth'].dt.to_timestamp()\n",
    "    monthly_results = pd.DataFrame({'YearMonth': df_monthly['YearMonth']})\n",
    "    monthly_results['State'] = state\n",
    "    # Perform rolling STL for each variable\n",
    "    for var, prefix in stl_features.items():\n",
    "        series = df_monthly[var]\n",
    "        stl = STL(series, period=12, robust=True)\n",
    "        res = stl.fit()\n",
    "        monthly_results[f'{prefix}_trend'] = res.trend\n",
    "        monthly_results[f'{prefix}_residual'] = res.resid\n",
    "    # De-seasonalize solar radiation (remove seasonal component)\n",
    "    solar_series = df_monthly[solar_radiation_col]\n",
    "    solar_stl = STL(solar_series, period=12, robust=True)\n",
    "    solar_res = solar_stl.fit()\n",
    "    monthly_results['Solar_de-seasonalized'] = solar_res.trend + solar_res.resid\n",
    "    stl_monthly_features.append(monthly_results)\n",
    "\n",
    "stl_monthly_df = pd.concat(stl_monthly_features, ignore_index=True)\n",
    "df_engineered['YearMonth'] = df_engineered['Date'].dt.to_period('M').dt.to_timestamp()\n",
    "# Merge\n",
    "columns_to_merge = ['State', 'YearMonth'] + [col for col in stl_monthly_df.columns if col not in ['YearMonth', 'State']]\n",
    "df_engineered = df_engineered.merge(stl_monthly_df, on=['State', 'YearMonth'], how='left')\n",
    "df_engineered = df_engineered.drop(columns=['YearMonth'])\n",
    "\n",
    "print(df_engineered.columns)\n",
    "exp_csv_path = os.path.join(target_dir, \"full_merged_data_all_features.csv\")\n",
    "df_engineered.to_csv(exp_csv_path, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_residual                    0.138212\n",
      "NDVI_std                         0.138151\n",
      "NDVI_trend                       0.137508\n",
      "Solar_de-seasonalized            0.137135\n",
      "Temperature_residual             0.136522\n",
      "Humidity_trend                   0.135862\n",
      "NDVI_var                         0.135521\n",
      "Humidity_residual                0.135198\n",
      "NDVI_mean                        0.135190\n",
      "Temperature_trend                0.134469\n",
      "Temperature [°C]_max             0.070649\n",
      "Temperature [°C]_mean            0.064331\n",
      "Temperature [°C]_min             0.055774\n",
      "Solar radiation [Jm2/day]_std    0.054594\n",
      "Solar radiation [Jm2/day]_max    0.052395\n",
      "Relative humidity [%]_mean       0.050675\n",
      "Solar radiation [Jm2/day]_sum    0.050072\n",
      "State                            0.048611\n",
      "Relative humidity [%]_min        0.047061\n",
      "Relative humidity [%]_max        0.045169\n",
      "Temperature [°C]_std             0.030598\n",
      "NDVI_max                         0.027498\n",
      "NDVI_min                         0.016999\n",
      "Precipitation [mm/day]_min       0.016438\n",
      "Wind speed [m/s]_std             0.013529\n",
      "Wind speed [m/s]_mean            0.012077\n",
      "Wind speed [m/s]_max             0.012060\n",
      "Wind speed [m/s]_min             0.011725\n",
      "Relative humidity [%]_std        0.011513\n",
      "Precipitation [mm/day]_sum       0.007524\n",
      "Precipitation [mm/day]_max       0.006323\n",
      "Precipitation [mm/day]_std       0.004929\n",
      "Solar radiation [Jm2/day]_min    0.004801\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### PREPROCESSING (encoding + scaling) ###\n",
    "\n",
    "full_df = df_engineered.copy()\n",
    "full_df['Date'] = pd.to_datetime(full_df['Date'])\n",
    "\n",
    "# Make target binary\n",
    "full_df['fire'] = full_df['fire'].astype(int)\n",
    "\n",
    "# Encode State\n",
    "le = LabelEncoder()\n",
    "full_df['State'] = le.fit_transform(full_df['State'])\n",
    "\n",
    "# Split\n",
    "train_df = full_df[(full_df['Date'].dt.year >= 2005) & (full_df['Date'].dt.year <= 2016)]\n",
    "val_df   = full_df[(full_df['Date'].dt.year >= 2017) & (full_df['Date'].dt.year <= 2018)]\n",
    "test_df  = full_df[(full_df['Date'].dt.year >= 2019) & (full_df['Date'].dt.year <= 2020)]\n",
    "\n",
    "protected_cols = ['Date', 'total_area_ha', 'log_total_area_ha', 'fire_count', 'outlier_type', 'ignition_cause', 'fire']\n",
    "all_columns = full_df.columns.tolist()\n",
    "\n",
    "# Columns to scale and use for MI\n",
    "features_to_scale = [col for col in all_columns if col not in protected_cols]\n",
    "scaler = MinMaxScaler()\n",
    "# Fit only on training features\n",
    "scaler.fit(train_df[features_to_scale])\n",
    "# Scale train separately\n",
    "train_scaled = train_df.copy()\n",
    "train_scaled[features_to_scale] = scaler.transform(train_df[features_to_scale])\n",
    "\n",
    "\n",
    "### SELECTION: MUTUAL INFORMATION ANALYSIS ###\n",
    "\n",
    "X_train = train_scaled[features_to_scale]\n",
    "y_train = train_scaled['fire']\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train, y_train, discrete_features=False, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=features_to_scale).sort_values(ascending=False)\n",
    "\n",
    "# Display ranked features\n",
    "print(mi_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Save Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE DATA S2 ###\n",
    "\n",
    "columns_to_keep = [\"total_area_ha\", \"log_total_area_ha\", \"fire_count\", \"outlier_type\", \"ignition_cause\", \"fire\",\n",
    "                   \"State\", \"Date\", \"NDVI_residual\", \"NDVI_std\", \"NDVI_trend\", \"Solar_de-seasonalized\", \"Temperature_residual\",\n",
    "                   \"Humidity_trend\", \"NDVI_var\", \"Humidity_residual\", \"NDVI_mean\", \"Temperature_trend\", \"Temperature [°C]_max\",\n",
    "                   \"Solar radiation [Jm2/day]_std\", \"Relative humidity [%]_mean\",\n",
    "                   \"Temperature [°C]_mean\", \"Solar radiation [Jm2/day]_sum\"\n",
    "                   ]\n",
    "\n",
    "df_engineered_filtered = df_engineered[columns_to_keep]\n",
    "\n",
    "exp_csv_path = os.path.join(target_dir, \"S2_full_merged_data.csv\")\n",
    "df_engineered_filtered.to_csv(exp_csv_path, index = True)\n",
    "\n",
    "full_df         = df_engineered_filtered.copy()\n",
    "full_df['Date'] = pd.to_datetime(full_df['Date'])\n",
    "full_df['fire'] = full_df['fire'].astype(int)\n",
    "\n",
    "# Split\n",
    "train_df = full_df[(full_df['Date'].dt.year >= 2005) & (full_df['Date'].dt.year <= 2016)]\n",
    "val_df   = full_df[(full_df['Date'].dt.year >= 2017) & (full_df['Date'].dt.year <= 2018)]\n",
    "test_df  = full_df[(full_df['Date'].dt.year >= 2019) & (full_df['Date'].dt.year <= 2020)]\n",
    "\n",
    "protected_cols    = [\"State\", 'Date', 'total_area_ha', 'log_total_area_ha', 'fire_count', 'outlier_type', 'ignition_cause', 'fire']\n",
    "all_columns       = full_df.columns.tolist()\n",
    "features_to_scale = [col for col in all_columns if col not in protected_cols]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# Fit only on training features\n",
    "scaler.fit(train_df[features_to_scale])\n",
    "# Scale train/val/test separately\n",
    "train_scaled = train_df.copy()\n",
    "val_scaled   = val_df.copy()\n",
    "test_scaled  = test_df.copy()\n",
    "\n",
    "train_scaled[features_to_scale] = scaler.transform(train_df[features_to_scale])\n",
    "val_scaled[features_to_scale]   = scaler.transform(val_df[features_to_scale])\n",
    "test_scaled[features_to_scale]  = scaler.transform(test_df[features_to_scale])\n",
    "\n",
    "full_scaled_df = pd.concat([train_scaled, val_scaled, test_scaled], axis=0)\n",
    "exp_csv_path   = os.path.join(target_dir, \"S2_full_merged_data_scaled.csv\")\n",
    "full_scaled_df.to_csv(exp_csv_path, index = True)\n",
    "\n",
    "exp_csv_path = os.path.join(target_dir, \"S2_scaled_train.csv\")\n",
    "train_scaled.to_csv(exp_csv_path, index = True)\n",
    "exp_csv_path = os.path.join(target_dir, \"S2_scaled_val.csv\")\n",
    "val_scaled.to_csv(exp_csv_path, index = True)\n",
    "exp_csv_path = os.path.join(target_dir, \"S2_scaled_test.csv\")\n",
    "test_scaled.to_csv(exp_csv_path, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SAVE DATA S1 ###\n",
    "\n",
    "columns_to_keep = [\"total_area_ha\", \"log_total_area_ha\", \"fire_count\", \"outlier_type\", \"ignition_cause\", \"fire\",\n",
    "                   \"State\", \"Date\", \"NDVI_residual\", \"NDVI_std\", \"NDVI_trend\", \"Solar_de-seasonalized\", \"Temperature_residual\",\n",
    "                   \"Humidity_trend\", \"NDVI_var\", \"Humidity_residual\", \"NDVI_mean\", \"Temperature_trend\", \"Temperature [°C]_max\",\n",
    "                   \"Solar radiation [Jm2/day]_std\", \"Relative humidity [%]_mean\",\n",
    "                   \"Temperature [°C]_mean\", \"Solar radiation [Jm2/day]_sum\"\n",
    "                   ]\n",
    "\n",
    "df_engineered_filtered = df_engineered[columns_to_keep]\n",
    "\n",
    "states_to_exclude = [\"Queensland\", \"South Australia\", \"Victoria\"]\n",
    "df_engineered_filtered = df_engineered_filtered[~df_engineered_filtered[\"State\"].isin(states_to_exclude)]\n",
    "\n",
    "exp_csv_path = os.path.join(target_dir, \"S1_full_merged_data.csv\")\n",
    "df_engineered_filtered.to_csv(exp_csv_path, index = True)\n",
    "\n",
    "full_df         = df_engineered_filtered.copy()\n",
    "full_df['Date'] = pd.to_datetime(full_df['Date'])\n",
    "full_df['fire'] = full_df['fire'].astype(int)\n",
    "\n",
    "# Split\n",
    "train_df = full_df[(full_df['Date'].dt.year >= 2005) & (full_df['Date'].dt.year <= 2016)]\n",
    "val_df   = full_df[(full_df['Date'].dt.year >= 2017) & (full_df['Date'].dt.year <= 2018)]\n",
    "test_df  = full_df[(full_df['Date'].dt.year >= 2019) & (full_df['Date'].dt.year <= 2020)]\n",
    "\n",
    "protected_cols    = [\"State\", 'Date', 'total_area_ha', 'log_total_area_ha', 'fire_count', 'outlier_type', 'ignition_cause', 'fire']\n",
    "all_columns       = full_df.columns.tolist()\n",
    "features_to_scale = [col for col in all_columns if col not in protected_cols]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# Fit only on training features\n",
    "scaler.fit(train_df[features_to_scale])\n",
    "# Scale train/val/test separately\n",
    "train_scaled = train_df.copy()\n",
    "val_scaled   = val_df.copy()\n",
    "test_scaled  = test_df.copy()\n",
    "\n",
    "train_scaled[features_to_scale] = scaler.transform(train_df[features_to_scale])\n",
    "val_scaled[features_to_scale]   = scaler.transform(val_df[features_to_scale])\n",
    "test_scaled[features_to_scale]  = scaler.transform(test_df[features_to_scale])\n",
    "\n",
    "full_scaled_df = pd.concat([train_scaled, val_scaled, test_scaled], axis=0)\n",
    "exp_csv_path   = os.path.join(target_dir, \"S1_full_merged_data_scaled.csv\")\n",
    "full_scaled_df.to_csv(exp_csv_path, index = True)\n",
    "\n",
    "exp_csv_path = os.path.join(target_dir, \"S1_scaled_train.csv\")\n",
    "train_scaled.to_csv(exp_csv_path, index = True)\n",
    "exp_csv_path = os.path.join(target_dir, \"S1_scaled_val.csv\")\n",
    "val_scaled.to_csv(exp_csv_path, index = True)\n",
    "exp_csv_path = os.path.join(target_dir, \"S1_scaled_test.csv\")\n",
    "test_scaled.to_csv(exp_csv_path, index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
